<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>OpenMP Parallelization</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../Blaze.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../blaze.jpg"/></td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">OpenMP Parallelization </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#openmp_setup">OpenMP Setup</a></li>
<li class="level1"><a href="#openmp_configuration">OpenMP Configuration</a></li>
<li class="level1"><a href="#openmp_first_touch">First Touch Policy</a></li>
<li class="level1"><a href="#openmp_limitations">Limitations of the OpenMP Parallelization</a><ul><li class="level2"><a href="#openmp_parallel">The Parallel Directive</a></li>
<li class="level2"><a href="#openmp_sections">The Sections Directive</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><p><br />
 </p>
<h1><a class="anchor" id="openmp_setup"></a>
OpenMP Setup</h1>
<hr/>
<p>To enable the OpenMP-based parallelization, all that needs to be done is to explicitly specify the use of OpenMP on the command line:</p>
<div class="fragment"><div class="line">-fopenmp   <span class="comment">// GNU C++ compiler</span></div><div class="line">-openmp    <span class="comment">// Intel C++ compiler</span></div><div class="line">/openmp    <span class="comment">// Visual Studio</span></div></div><!-- fragment --><p>This simple action will cause the <b>Blaze</b> library to automatically try to run all operations in parallel with the specified number of threads.</p>
<p>As common for OpenMP, the number of threads can be specified either via an environment variable</p>
<div class="fragment"><div class="line">export OMP_NUM_THREADS=4  <span class="comment">// Unix systems</span></div><div class="line"><span class="keyword">set</span> OMP_NUM_THREADS=4     <span class="comment">// Windows systems</span></div></div><!-- fragment --><p>or via an explicit call to the <code>omp_set_num_threads()</code> function:</p>
<div class="fragment"><div class="line">omp_set_num_threads( 4 );</div></div><!-- fragment --><p>Alternatively, the number of threads can also be specified via the <code><a class="el" href="../../dc/d00/group__smp.html#ga5434a72b76ef2fcf1ecb9901689f8159" title="Sets the number of threads to be used for thread parallel operations. ">setNumThreads()</a></code> function provided by the <b>Blaze</b> library:</p>
<div class="fragment"><div class="line"><a class="code" href="../../dc/d00/group__smp.html#ga5434a72b76ef2fcf1ecb9901689f8159">blaze::setNumThreads</a>( 4 );</div></div><!-- fragment --><p>Please note that the <b>Blaze</b> library does not limit the available number of threads. Therefore it is in YOUR responsibility to choose an appropriate number of threads. The best performance, though, can be expected if the specified number of threads matches the available number of cores.</p>
<p>In order to query the number of threads used for the parallelization of operations, the <code><a class="el" href="../../dc/d00/group__smp.html#ga3d5444159a291c35ca703ae5d58366ad" title="Returns the number of threads used for thread parallel operations. ">getNumThreads()</a></code> function can be used:</p>
<div class="fragment"><div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> threads = <a class="code" href="../../dc/d00/group__smp.html#ga3d5444159a291c35ca703ae5d58366ad">blaze::getNumThreads</a>();</div></div><!-- fragment --><p>In the context of OpenMP, the function returns the maximum number of threads OpenMP will use within a parallel region and is therefore equivalent to the <code>omp_get_max_threads()</code> function.</p>
<p><br />
 </p>
<h1><a class="anchor" id="openmp_configuration"></a>
OpenMP Configuration</h1>
<hr/>
<p>Note that <b>Blaze</b> is not unconditionally running an operation in parallel. In case <b>Blaze</b> deems the parallel execution as counterproductive for the overall performance, the operation is executed serially. One of the main reasons for not executing an operation in parallel is the size of the operands. For instance, a vector addition is only executed in parallel if the size of both vector operands exceeds a certain threshold. Otherwise, the performance could seriously decrease due to the overhead caused by the thread setup. However, in order to be able to adjust the <b>Blaze</b> library to a specific system, it is possible to configure these thresholds manually. All shared memory thresholds are contained within the configuration file <code>./blaze/config/Thresholds.h</code>.</p>
<p>Please note that these thresholds are highly sensitiv to the used system architecture and the shared memory parallelization technique (see also <a class="el" href="../../db/d46/cpp_threads_parallelization.html">C++11 Thread Parallelization</a> and <a class="el" href="../../d9/d05/boost_threads_parallelization.html">Boost Thread Parallelization</a>). Therefore the default values cannot guarantee maximum performance for all possible situations and configurations. They merely provide a reasonable standard for the current CPU generation.</p>
<p><br />
 </p>
<h1><a class="anchor" id="openmp_first_touch"></a>
First Touch Policy</h1>
<hr/>
<p>So far the <b>Blaze</b> library does not (yet) automatically initialize dynamic memory according to the first touch principle. Consider for instance the following vector triad example:</p>
<div class="fragment"><div class="line"><span class="keyword">using</span> <a class="code" href="../../d2/de9/namespaceblaze.html#acee466faebcaba59afde0fbfe22041aa">blaze::columnVector</a>;</div><div class="line"></div><div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> N( 1000000UL );</div><div class="line"></div><div class="line"><a class="code" href="../../da/d9e/classblaze_1_1DynamicVector.html">blaze::DynamicVector&lt;double,columnVector&gt;</a> a( N ), b( N ), c( N ), d( N );</div><div class="line"></div><div class="line"><span class="comment">// Initialization of the vectors b, c, and d</span></div><div class="line"><span class="keywordflow">for</span>( <span class="keywordtype">size_t</span> i=0UL; i&lt;N; ++i ) {</div><div class="line">   b[i] = rand&lt;double&gt;();</div><div class="line">   c[i] = rand&lt;double&gt;();</div><div class="line">   d[i] = rand&lt;double&gt;();</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">// Performing a vector triad</span></div><div class="line">a = b + c * d;</div></div><!-- fragment --><p>If this code, which is prototypical for many OpenMP applications that have not been optimized for ccNUMA architectures, is run across several locality domains (LD), it will not scale beyond the maximum performance achievable on a single LD if the working set does not fit into the cache. This is because the initialization loop is executed by a single thread, writing to <code>b</code>, <code>c</code>, and <code>d</code> for the first time. Hence, all memory pages belonging to those arrays will be mapped into a single LD.</p>
<p>As mentioned above, this problem can be solved by performing vector initialization in parallel:</p>
<div class="fragment"><div class="line"><span class="comment">// ...</span></div><div class="line"></div><div class="line"><span class="comment">// Initialization of the vectors b, c, and d</span></div><div class="line"><span class="preprocessor">#pragma omp parallel for</span></div><div class="line"><span class="keywordflow">for</span>( <span class="keywordtype">size_t</span> i=0UL; i&lt;N; ++i ) {</div><div class="line">   b[i] = rand&lt;double&gt;();</div><div class="line">   c[i] = rand&lt;double&gt;();</div><div class="line">   d[i] = rand&lt;double&gt;();</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">// ...</span></div></div><!-- fragment --><p>This simple modification makes a huge difference on ccNUMA in memory-bound situations (as for instance in all BLAS level 1 operations and partially BLAS level 2 operations). Therefore, in order to achieve the maximum possible performance, it is imperative to initialize the memory according to the later use of the data structures.</p>
<p><br />
 </p>
<h1><a class="anchor" id="openmp_limitations"></a>
Limitations of the OpenMP Parallelization</h1>
<hr/>
<p>There are a few important limitations to the current <b>Blaze</b> OpenMP parallelization. The first one involves the explicit use of an OpenMP parallel region (see <a class="el" href="../../d4/d55/openmp_parallelization.html#openmp_parallel">The Parallel Directive</a>), the other one the OpenMP <code>sections</code> directive (see <a class="el" href="../../d4/d55/openmp_parallelization.html#openmp_sections">The Sections Directive</a>).</p>
<p><br />
 </p>
<h2><a class="anchor" id="openmp_parallel"></a>
The Parallel Directive</h2>
<p>In OpenMP threads are explicitly spawned via the an OpenMP parallel directive:</p>
<div class="fragment"><div class="line"><span class="comment">// Serial region, executed by a single thread</span></div><div class="line"></div><div class="line"><span class="preprocessor">#pragma omp parallel</span></div><div class="line">{</div><div class="line">   <span class="comment">// Parallel region, executed by the specified number of threads</span></div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">// Serial region, executed by a single thread</span></div></div><!-- fragment --><p>Conceptually, the specified number of threads (see <a class="el" href="../../d4/d55/openmp_parallelization.html#openmp_setup">OpenMP Setup</a>) is created every time a parallel directive is encountered. Therefore, from a performance point of view, it seems to be beneficial to use a single OpenMP parallel directive for several operations:</p>
<div class="fragment"><div class="line"><a class="code" href="../../da/d9e/classblaze_1_1DynamicVector.html">blaze::DynamicVector&lt;double&gt;</a> x, y1, y2;</div><div class="line"><a class="code" href="../../de/d1e/classblaze_1_1DynamicMatrix.html">blaze::DynamicMatrix&lt;double&gt;</a> A, B;</div><div class="line"></div><div class="line"><span class="preprocessor">#pragma omp parallel</span></div><div class="line">{</div><div class="line">   y1 = A * x;</div><div class="line">   y2 = B * x;</div><div class="line">}</div></div><!-- fragment --><p>Unfortunately, this optimization approach is not allowed within the <b>Blaze</b> library. More explicitly, it is not allowed to put an operation into a parallel region. The reason is that the entire code contained within a parallel region is executed by all threads. Although this appears to just comprise the contained computations, a computation (or more specifically the assignment of an expression to a vector or matrix) can contain additional logic that must not be handled by multiple threads (as for instance memory allocations, setup of temporaries, etc.). Therefore it is not possible to manually start a parallel region for several operations, but <b>Blaze</b> will spawn threads automatically, depending on the specifics of the operation at hand and the given operands.</p>
<p><br />
 </p>
<h2><a class="anchor" id="openmp_sections"></a>
The Sections Directive</h2>
<p>OpenMP provides several work-sharing construct to distribute work among threads. One of these constructs is the <code>sections</code> directive:</p>
<div class="fragment"><div class="line"><a class="code" href="../../da/d9e/classblaze_1_1DynamicVector.html">blaze::DynamicVector&lt;double&gt;</a> x, y1, y2;</div><div class="line"><a class="code" href="../../de/d1e/classblaze_1_1DynamicMatrix.html">blaze::DynamicMatrix&lt;double&gt;</a> A, B;</div><div class="line"></div><div class="line"><span class="comment">// ... Resizing and initialization</span></div><div class="line"></div><div class="line"><span class="preprocessor">#pragma omp sections</span></div><div class="line">{</div><div class="line"><span class="preprocessor">#pragma omp section</span></div><div class="line"></div><div class="line">   y1 = A * x;</div><div class="line"></div><div class="line"><span class="preprocessor">#pragma omp section</span></div><div class="line"></div><div class="line">   y2 = B * x;</div><div class="line"></div><div class="line">}</div></div><!-- fragment --><p>In this example, two threads are used to compute two distinct matrix/vector multiplications concurrently. Thereby each of the <code>sections</code> is executed by exactly one thread.</p>
<p>Unfortunately <b>Blaze</b> does not support concurrent parallel computations and therefore this approach does not work with any of the <b>Blaze</b> parallelization techniques. All techniques (including the C++11 and Boost thread parallelizations; see <a class="el" href="../../db/d46/cpp_threads_parallelization.html">C++11 Thread Parallelization</a> and <a class="el" href="../../d9/d05/boost_threads_parallelization.html">Boost Thread Parallelization</a>) are optimized for the parallel computation of an operation within a single thread of execution. This means that <b>Blaze</b> tries to use all available threads to compute the result of a single operation as efficiently as possible. Therefore, for this special case, it is advisable to disable all <b>Blaze</b> parallelizations and to let <b>Blaze</b> compute all operations within a <code>sections</code> directive in serial. This can be done by either completely disabling the <b>Blaze</b> parallelization (see <a class="el" href="../../d9/dce/serial_execution.html">Serial Execution</a>) or by selectively serializing all operations within a <code>sections</code> directive via the <code><a class="el" href="../../db/df0/group__dense__matrix.html#gac775fabaa100b5d7367998d1ea31e5fb" title="Forces the serial evaluation of the given dense matrix expression dm. ">serial()</a></code> function:</p>
<div class="fragment"><div class="line"><a class="code" href="../../da/d9e/classblaze_1_1DynamicVector.html">blaze::DynamicVector&lt;double&gt;</a> x, y1, y2;</div><div class="line"><a class="code" href="../../de/d1e/classblaze_1_1DynamicMatrix.html">blaze::DynamicMatrix&lt;double&gt;</a> A, B;</div><div class="line"></div><div class="line"><span class="comment">// ... Resizing and initialization</span></div><div class="line"></div><div class="line"><span class="preprocessor">#pragma omp sections</span></div><div class="line">{</div><div class="line"><span class="preprocessor">#pragma omp section</span></div><div class="line"></div><div class="line">   y1 = <a class="code" href="../../db/df0/group__dense__matrix.html#gac775fabaa100b5d7367998d1ea31e5fb">serial</a>( A * x );</div><div class="line"></div><div class="line"><span class="preprocessor">#pragma omp section</span></div><div class="line"></div><div class="line">   y2 = <a class="code" href="../../db/df0/group__dense__matrix.html#gac775fabaa100b5d7367998d1ea31e5fb">serial</a>( B * x );</div><div class="line"></div><div class="line">}</div></div><!-- fragment --><p>Please note that the use of the <code>BLAZE_SERIAL_SECTION</code> (see also <a class="el" href="../../d9/dce/serial_execution.html">Serial Execution</a>) does NOT work in this context!</p>
<p><br />
 Previous: <a class="el" href="../../df/d92/shared_memory_parallelization.html">Shared Memory Parallelization</a> &#160; &#160; Next: <a class="el" href="../../db/d46/cpp_threads_parallelization.html">C++11 Thread Parallelization</a> </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Aug 18 2017 05:50:23 by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
